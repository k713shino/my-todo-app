import { NextRequest, NextResponse } from 'next/server'
import { getAuthSession, isAuthenticated } from '@/lib/session-utils'
import { extractUserIdFromPrefixed } from '@/lib/user-id-utils'
import { lambdaAPI } from '@/lib/lambda-api'
import { CacheManager } from '@/lib/cache'

// CSVãƒ†ã‚­ã‚¹ãƒˆã‚’å®‰å…¨ã«è§£æï¼ˆå¼•ç”¨ç¬¦ãƒ»æ”¹è¡Œãƒ»äºŒé‡å¼•ç”¨ç¬¦ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—å¯¾å¿œï¼‰
function parseCSVText(text: string): { headers: string[]; rows: string[][] } {
  try {
    if (!text || text.trim().length === 0) {
      console.log('âš ï¸ Empty CSV content')
      return { headers: [], rows: [] }
    }

    console.log('ğŸ“‹ CSVè§£æè©³ç´°:', {
      length: text.length,
      startsWithBOM: text.charCodeAt(0) === 0xFEFF,
      firstChars: text.substring(0, 50),
      containsComma: text.includes(','),
      containsNewline: text.includes('\n')
    })

    // UTF-8 BOMé™¤å»
    if (text.charCodeAt(0) === 0xFEFF) {
      text = text.slice(1)
      console.log('âœ“ BOM removed')
    }

    const rows: string[][] = []
    let row: string[] = []
    let field = ''
    let inQuotes = false

    for (let i = 0; i < text.length; i++) {
      const ch = text[i]
      if (inQuotes) {
        if (ch === '"') {
          const next = text[i + 1]
          if (next === '"') { field += '"'; i++ } else { inQuotes = false }
        } else { field += ch }
      } else {
        if (ch === '"') inQuotes = true
        else if (ch === ',') { row.push(field); field = '' }
        else if (ch === '\n') { row.push(field); rows.push(row); row = []; field = '' }
        else if (ch === '\r') { /* CRLFç„¡è¦– */ }
        else { field += ch }
      }
    }

    // æœ€å¾Œã®è¡Œã‚’è¿½åŠ 
    row.push(field)
    if (row.some(c => c.trim().length > 0)) {
      rows.push(row)
    }

    console.log('ğŸ“‹ CSVè§£æä¸­é–“çµæœ:', {
      totalRows: rows.length,
      firstRow: rows[0],
      hasMultipleRows: rows.length > 1
    })

    const nonEmpty = rows.filter(r => r.some(c => c.trim().length > 0))
    const headers = (nonEmpty[0] || []).map(h => h.trim())
    const dataRows = nonEmpty.slice(1)

    console.log('ğŸ“‹ CSVæœ€çµ‚çµæœ:', {
      headers,
      dataRowsCount: dataRows.length
    })

    return { headers, rows: dataRows }
  } catch (error) {
    console.error('âŒ CSV parsing error:', error)
    throw new Error(`CSV parsing failed: ${error instanceof Error ? error.message : String(error)}`)
  }
}

export async function POST(request: NextRequest) {
  try {
    console.log('ğŸ“¥ Data import API called')
    
    const session = await getAuthSession()
    console.log('Session:', session ? { userId: session.user?.id, email: session.user?.email } : 'null')
    
    if (!isAuthenticated(session)) {
      console.log('âŒ Unauthorized access attempt')
      return NextResponse.json({ error: 'Unauthorized' }, { status: 401 })
    }

    const formData = await request.formData()
    const file = formData.get('file') as File
    console.log('File:', file ? { name: file.name, size: file.size, type: file.type } : 'null')

    if (!file) {
      return NextResponse.json({ error: 'No file uploaded' }, { status: 400 })
    }

    // ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ãƒã‚§ãƒƒã‚¯
    const allowedTypes = ['application/json', 'text/csv', 'text/plain']
    const isValidType = allowedTypes.includes(file.type) || 
                       file.name.endsWith('.json') || 
                       file.name.endsWith('.csv')

    if (!isValidType) {
      return NextResponse.json({ 
        error: 'Invalid file format. Only JSON and CSV files are allowed.' 
      }, { status: 400 })
    }

    // ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯ (10MB)
    if (file.size > 10 * 1024 * 1024) {
      return NextResponse.json({ 
        error: 'File size too large. Maximum size is 10MB.' 
      }, { status: 400 })
    }

    // ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã‚’èª­ã¿å–ã‚Š
    const fileContent = await file.text()
    let todoData: Record<string, unknown>[] = []

    console.log('ğŸ“„ ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±:', {
      fileName: file.name,
      fileType: file.type,
      fileSize: file.size,
      endsWithCSV: file.name.endsWith('.csv'),
      endsWithJSON: file.name.endsWith('.json'),
      contentLength: fileContent.length,
      firstLine: fileContent.split('\n')[0]
    })

    // ãƒ¦ãƒ¼ã‚¶ãƒ¼IDï¼ˆæ¥é ­è¾é™¤å»ï¼‰ã‚’å…ˆã«ç¢ºå®šï¼ˆå¾Œç¶šã§ã‚‚åˆ©ç”¨ï¼‰
    const actualUserId = extractUserIdFromPrefixed(session.user.id)
    // æ—¢å­˜ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®Todoã‚’å–å¾—ï¼ˆé‡è¤‡æ¤œçŸ¥ã®ãŸã‚ï¼‰
    const existingTodos = await lambdaAPI.getUserTodos(actualUserId) as unknown as Record<string, unknown>[]

    // æ–‡å­—åˆ—æ­£è¦åŒ–ï¼ˆNFKC + å°æ–‡å­— + å¥èª­ç‚¹/è¨˜å·/ä½™åˆ†ãªç©ºç™½é™¤å»ï¼‰
    const normalizeStr = (s: string) => (s || '')
      .normalize('NFKC')
      .toLowerCase()
      .replace(/[\p{P}\p{S}]/gu, ' ')
      .replace(/\s+/g, ' ')
      .trim()
    // ãƒˆãƒ¼ã‚¯ãƒ³åŒ–
    const tokenize = (s: string) => new Set(normalizeStr(s).split(' ').filter(Boolean))
    // Jaccardé¡ä¼¼åº¦
    const jaccard = (a: Set<string>, b: Set<string>) => {
      if (a.size === 0 && b.size === 0) return 1
      let inter = 0
      for (const t of a) if (b.has(t)) inter++
      const uni = a.size + b.size - inter
      return uni === 0 ? 1 : inter / uni
    }
    const eqDay = (d1?: string | null, d2?: string | null) => {
      if (!d1 && !d2) return true
      if (!d1 || !d2) return false
      const a = new Date(d1)
      const b = new Date(d2)
      if (isNaN(a.getTime()) || isNaN(b.getTime())) return d1 === d2
      const da = `${a.getFullYear()}-${a.getMonth()+1}-${a.getDate()}`
      const db = `${b.getFullYear()}-${b.getMonth()+1}-${b.getDate()}`
      return da === db
    }
    const eqNullable = (x?: string | null, y?: string | null) => (x || '') === (y || '')

    const existingIndexByTitle = new Map<string, Record<string, unknown>[]>()
    for (const e of existingTodos) {
      const key = normalizeStr(e.title as string)
      const arr = existingIndexByTitle.get(key) || []
      arr.push(e)
      existingIndexByTitle.set(key, arr)
    }

    const isDuplicateOfExisting = (t: Record<string, unknown>): Record<string, unknown> | null => {
      const key = normalizeStr(t.title as string)
      const candidates = [
        ...(existingIndexByTitle.get(key) || []),
        // é¡ä¼¼ã‚¿ã‚¤ãƒˆãƒ«å€™è£œï¼ˆç°¡æ˜“æ¢ç´¢ï¼‰: åŒã˜å…ˆé ­èªã‚’å«ã‚€ã‚‚ã®
        ...Array.from(existingIndexByTitle.entries())
          .filter(([k]) => k !== key && (k.includes(key) || key.includes(k)))
          .flatMap(([, v]) => v)
      ]
      const tTokens = tokenize(t.title as string)
      let best: Record<string, unknown> | null = null
      let bestScore = 0
      for (const c of candidates) {
        const score = jaccard(tTokens, tokenize(c.title as string))
        // å³å¯†ä¸€è‡´ or é«˜é¡ä¼¼åº¦ + é‡è¦ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ä¸€è‡´ã§é‡è¤‡åˆ¤å®š
        const exact = normalizeStr(c.title as string) === key
        const strongSimilar = score >= 0.9
        const dateOk = eqDay(t.dueDate as string | null | undefined, c.dueDate as string | null | undefined)
        const catOk = eqNullable(t.category as string | null | undefined, c.category as string | null | undefined)
        if ((exact || strongSimilar) && dateOk && catOk) {
          if (score > bestScore) { best = c; bestScore = score }
        }
      }
      return best
    }

    // ãƒãƒƒãƒå†…é‡è¤‡ï¼ˆoriginalIdå„ªå…ˆã€ãªã‘ã‚Œã°ã‚­ãƒ¼åˆæˆï¼‰ã‚’ã‚¹ã‚­ãƒƒãƒ—
    const seen = new Set<string>()
    const batchKey = (t: Record<string, unknown>) => {
      if (t.originalId) return `oid:${String(t.originalId)}`
      return `k:${normalizeStr(t.title as string)}|d:${t.dueDate ? new Date(t.dueDate as string).toDateString() : 'none'}|c:${(t.category||'')}`
    }

    try {
      console.log('ğŸ“„ ãƒ•ã‚¡ã‚¤ãƒ«è§£æé–‹å§‹:', {
        fileName: file.name,
        fileType: file.type,
        fileSize: file.size,
        contentPreview: fileContent.substring(0, 200)
      })

      // ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã‚’å†…å®¹ã‹ã‚‰ã‚‚åˆ¤å®š
      const isJsonContent = fileContent.trim().startsWith('{') || fileContent.trim().startsWith('[')
      const isJsonFile = file.name.endsWith('.json')
      const isCsvFile = file.name.endsWith('.csv')

      console.log('ğŸ“„ å½¢å¼åˆ¤å®š:', {
        isJsonFile,
        isCsvFile,
        isJsonContent,
        firstChar: fileContent.trim()[0]
      })

      if (isJsonFile || (isJsonContent && !isCsvFile)) {
        const jsonData = JSON.parse(fileContent)

        // GDPRæº–æ‹ ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå½¢å¼ã®æ§‹é€ ãƒã‚§ãƒƒã‚¯
        if (jsonData.todos && Array.isArray(jsonData.todos)) {
          // GDPRæº–æ‹ ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆæ¨å¥¨å½¢å¼ï¼‰
          todoData = jsonData.todos
          console.log('ğŸ“‹ GDPRæº–æ‹ ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå½¢å¼ã‚’æ¤œå‡º:', {
            exportInfo: jsonData.exportInfo?.version || 'unknown',
            userInfo: jsonData.user?.id || 'unknown',
            todoCount: jsonData.todos.length,
            hasStatistics: !!jsonData.statistics
          })
        } else if (Array.isArray(jsonData)) {
          // å¾“æ¥ã®é…åˆ—å½¢å¼
          todoData = jsonData
          console.log('ğŸ“‹ å¾“æ¥ã®é…åˆ—å½¢å¼ã‚’æ¤œå‡º:', { todoCount: jsonData.length })
        } else {
          throw new Error('Invalid JSON structure. Expected format: {todos: [...]} or [...]')
        }
      } else if (isCsvFile) {
        console.log('ğŸ“‹ CSVè§£æé–‹å§‹...')
        console.log('ğŸ“‹ CSVç”Ÿãƒ‡ãƒ¼ã‚¿ï¼ˆæœ€åˆã®300æ–‡å­—ï¼‰:', fileContent.substring(0, 300))

        // CSVè§£æï¼ˆå¼•ç”¨ç¬¦ãƒ»æ”¹è¡Œå¯¾å¿œï¼‰
        const { headers, rows } = parseCSVText(fileContent)
        console.log('ğŸ“‹ CSVè§£æçµæœ:', {
          headersCount: headers.length,
          rowsCount: rows.length,
          headers: headers,
          firstRow: rows[0]
        })

        if (headers.length === 0 || rows.length === 0) {
          throw new Error(`CSV file must have header and at least one data row. Found ${headers.length} headers and ${rows.length} rows`)
        }
        console.log('ğŸ“‹ CSVãƒ˜ãƒƒãƒ€ãƒ¼ã‚’æ¤œå‡º:', headers)
        
        // GDPRæº–æ‹ ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå½¢å¼ã®ãƒ˜ãƒƒãƒ€ãƒ¼ãƒã‚§ãƒƒã‚¯
        const expectedHeaders = ['ID', 'Title', 'Description', 'Status', 'Completed', 'Priority', 'Category', 'Tags', 'Parent ID', 'Due Date', 'Created At', 'Updated At']
        const hasGDPRFormat = expectedHeaders.some(header => headers.includes(header))
        
        if (hasGDPRFormat) {
          console.log('ğŸ“‹ GDPRæº–æ‹ CSVã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå½¢å¼ã‚’æ¤œå‡º')
        }
        
        // æœ€ä½é™å¿…è¦ãªãƒ˜ãƒƒãƒ€ãƒ¼ãƒã‚§ãƒƒã‚¯
        console.log('ğŸ“‹ ãƒ˜ãƒƒãƒ€ãƒ¼æ¤œè¨¼:', {
          headers,
          headersLowerCase: headers.map(h => h.toLowerCase()),
          hasTitleEnglish: headers.includes('Title'),
          hasTitleJapanese: headers.includes('ã‚¿ã‚¤ãƒˆãƒ«'),
          hasTitleLowerCase: headers.some(h => h.toLowerCase() === 'title')
        })

        const titleHeader = headers.find(h =>
          h.toLowerCase() === 'title' ||
          h === 'Title' ||
          h === 'ã‚¿ã‚¤ãƒˆãƒ«' ||
          h.toLowerCase() === 'ã‚¿ã‚¤ãƒˆãƒ«'
        )

        if (!titleHeader) {
          console.error('âŒ Title column not found. Available headers:', headers)
          throw new Error(`CSV must contain a "Title" or "ã‚¿ã‚¤ãƒˆãƒ«" column. Found headers: ${headers.join(', ')}`)
        }

        console.log('âœ… Title header found:', titleHeader)

        todoData = rows.map(values => {

          const todo: Record<string, unknown> = {}
          
          headers.forEach((header, index) => {
            const value = (values[index] ?? '').trim()
            if (value) {
              // ãƒ˜ãƒƒãƒ€ãƒ¼åã‚’æ¨™æº–å½¢å¼ã«ãƒãƒƒãƒ”ãƒ³ã‚°
              switch (header) {
                case 'ID':
                  todo.originalId = value
                  break
                case 'Title':
                  todo.title = value
                  break
                case 'Description':
                  todo.description = value
                  break
                case 'Status':
                  todo.status = value
                  break
                case 'Completed':
                  todo.completed = value.toLowerCase() === 'true'
                  break
                case 'Priority':
                  todo.priority = value
                  console.log('ğŸ” CSV Priorityå‡¦ç†:', { header, value, result: value })
                  break
                case 'Category':
                  todo.category = value
                  break
                case 'Tags':
                  todo.tags = value
                  break
                case 'Due Date':
                  todo.dueDate = value
                  break
                case 'Created At':
                  todo.createdAt = value
                  break
                case 'Updated At':
                  todo.updatedAt = value
                  break
                default:
                  // å°æ–‡å­—ã®ãƒ˜ãƒƒãƒ€ãƒ¼ã‚‚ã‚µãƒãƒ¼ãƒˆ
                  todo[header.toLowerCase()] = value
                  break
              }
            }
          })
          
          return todo
        }).filter(todo => todo.title) // ã‚¿ã‚¤ãƒˆãƒ«ãŒã‚ã‚‹ã‚‚ã®ã®ã¿
      }
    } catch (parseError) {
      console.error('âŒ File parsing error:', parseError)
      const errorMessage = parseError instanceof Error ? parseError.message : String(parseError)
      return NextResponse.json({
        error: `Failed to parse file: ${errorMessage}. Please check the file format.`
      }, { status: 400 })
    }

    if (todoData.length === 0) {
      return NextResponse.json({ 
        error: 'No valid todo items found in the file.' 
      }, { status: 400 })
    }

    // GDPRæº–æ‹ ãƒ‡ãƒ¼ã‚¿ã®æ­£è¦åŒ–ã¨ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
    const normalizedTodos = todoData.map(todo => {
      // åŸºæœ¬çš„ãªãƒ‡ãƒ¼ã‚¿æ­£è¦åŒ–
      // å„ªå…ˆåº¦ã‚’å¤§æ–‡å­—ã«å¤‰æ›ï¼ˆUIã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®è¦æ±‚ã«åˆã‚ã›ã‚‹ï¼‰
      const priorityValue = (() => {
        const pRaw = (todo.priority || '').toString()
        const p = pRaw.toUpperCase()
        if (['LOW','MEDIUM','HIGH','URGENT'].includes(p)) return p
        const lower = pRaw.toLowerCase()
        if (['low','medium','high','urgent'].includes(lower)) return lower.toUpperCase()
        return 'MEDIUM'
      })()
      
      console.log('ğŸ” å„ªå…ˆåº¦æ­£è¦åŒ–:', { 
        originalPriority: todo.priority, 
        normalizedPriority: priorityValue,
        title: todo.title 
      })
      
      const statusValue = (() => {
        const sRaw = (todo.status || '').toString()
        const s = sRaw.toUpperCase()
        if (['TODO','IN_PROGRESS','REVIEW','DONE'].includes(s)) return s
        if (todo.completed === true) return 'DONE'
        if (todo.completed === false) return 'TODO'
        return 'TODO'
      })()

      const normalized: Record<string, unknown> = {
        title: todo.title || 'Untitled',
        description: todo.description || '',
        status: statusValue,
        priority: priorityValue,
        category: todo.category || null,
        dueDate: todo.dueDate ? new Date(String(todo.dueDate)).toISOString() : null,
        tags: Array.isArray(todo.tags)
          ? todo.tags
          : (typeof todo.tags === 'string' && todo.tags.length > 0
              ? todo.tags.split(',').map((t: string) => t.trim()).filter(Boolean)
              : [])
      }
      
      // GDPRæº–æ‹ ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã®è¿½åŠ ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’ä¿æŒ
      if (todo.completed !== undefined) {
        normalized.completed = Boolean(todo.completed)
      }
      
      // å…ƒã®IDãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯ä¿æŒï¼ˆé‡è¤‡ãƒã‚§ãƒƒã‚¯ç”¨ï¼‰
      if (todo.originalId || todo.id) {
        normalized.originalId = todo.originalId || todo.id
      }
      // ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—æƒ…å ±ã®ä¿æŒï¼ˆå‚è€ƒæƒ…å ±ã¨ã—ã¦ï¼‰
      if (todo.createdAt) {
        normalized.originalCreatedAt = todo.createdAt
      }
      if (todo.updatedAt) {
        normalized.originalUpdatedAt = todo.updatedAt
      }
      
      return normalized
    }).filter(todo => (todo.title as string).trim().length > 0)
    
    console.log('ğŸ“Š æ­£è¦åŒ–ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«:', {
      totalCount: normalizedTodos.length,
      hasCompleted: normalizedTodos.some(t => t.completed !== undefined),
      hasOriginalIds: normalizedTodos.some(t => t.originalId),
      hasTimestamps: normalizedTodos.some(t => t.originalCreatedAt),
      sampleData: normalizedTodos.slice(0, 2).map(t => ({
        title: t.title,
        completed: t.completed,
        priority: t.priority,
        originalId: t.originalId,
        hasTimestamp: !!t.originalCreatedAt
      }))
    })
    
    console.log('ğŸ” å„ªå…ˆåº¦ã®è©³ç´°ãƒã‚§ãƒƒã‚¯:', {
      priorities: normalizedTodos.map(t => ({ title: t.title, priority: t.priority, originalPriority: todoData.find(orig => orig.title === t.title)?.priority }))
    })

      console.log('ğŸ“Š Import request details:', {
        userId: actualUserId,
        userEmail: session.user.email,
        userName: session.user.name,
        todoCount: normalizedTodos.length,
        sampleTodos: normalizedTodos.slice(0, 2).map(t => ({ title: t.title, priority: t.priority }))
      })

      // ãƒãƒƒãƒå†…é‡è¤‡ï¼ˆoriginalIdå„ªå…ˆã€ãªã‘ã‚Œã°ã‚­ãƒ¼åˆæˆï¼‰ã‚’é™¤ã„ãŸé…åˆ—ã‚’ä½œæˆ
      const uniqueTodos = normalizedTodos.filter(t => {
        const key = batchKey(t)
        if (seen.has(key)) return false
        seen.add(key)
        return true
      })

    try {
      // ä¸¦åˆ—åº¦ï¼ˆåŒæ™‚å®Ÿè¡Œæ•°ï¼‰ã‚’ç’°å¢ƒå¤‰æ•°ã§åˆ¶å¾¡ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ4ã€‚
      const CONCURRENCY = Math.max(1, parseInt(process.env.IMPORT_CONCURRENCY || '4', 10) || 4)

      // ã‚·ãƒ³ãƒ—ãƒ«ãªä¸¦åˆ—ãƒ¯ãƒ¼ã‚«ãƒ¼å®Ÿè£…
      const runWithConcurrency = async <T>(
        items: T[],
        worker: (item: T, index: number) => Promise<void>,
        limit = CONCURRENCY
      ) => {
        let cursor = 0
        const workers = new Array(Math.min(limit, items.length)).fill(0).map(async () => {
          while (true) {
            const myIndex = cursor++
            if (myIndex >= items.length) break
            await worker(items[myIndex], myIndex)
          }
        })
        await Promise.all(workers)
      }

      let importedCount = 0
      let skippedCount = 0

      const createOne = async (payload: Record<string, unknown>) => {
        const res = await lambdaAPI.post('/todos', {
          title: payload.title,
          description: payload.description || undefined,
          userId: actualUserId,
          userEmail: session.user.email || undefined,
          userName: session.user.name || undefined,
          priority: payload.priority || 'MEDIUM',
          status: payload.status || 'TODO',
          dueDate: payload.dueDate || undefined,
          category: payload.category || undefined,
          tags: Array.isArray(payload.tags) ? payload.tags : undefined,
        })
        if (res.success && res.data) {
          importedCount++
          return res.data
        } else {
          skippedCount++
          return null
        }
      }

      await runWithConcurrency(uniqueTodos, async (t) => {
        const dup = isDuplicateOfExisting(t)
        if (dup) {
          skippedCount++
          return
        }
        await createOne(t)
      })

      const totalCount = uniqueTodos.length
      console.log('ğŸ“ˆ Import results (parallelized):', { importedCount, skippedCount, totalCount, concurrency: CONCURRENCY })

      // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç„¡åŠ¹åŒ–
      try { await CacheManager.invalidateUserTodos(session.user.id) } catch {}

      return NextResponse.json({
        success: true,
        importedCount,
        skippedCount,
        totalCount,
        message: importedCount > 0
          ? `Successfully imported ${importedCount} todos${skippedCount > 0 ? ` (${skippedCount} skipped)` : ''}`
          : `All ${totalCount} todos were skipped due to errors or duplicates`
      })

    } catch (error) {
      console.error('Import processing error:', error)
      return NextResponse.json({ error: 'Internal server error' }, { status: 500 })
    }

  } catch (error) {
    console.error('Import API error:', error)
    return NextResponse.json({ 
      error: 'Internal server error' 
    }, { status: 500 })
  }
}
